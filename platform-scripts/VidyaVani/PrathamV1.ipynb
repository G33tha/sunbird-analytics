{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "................\n",
      "Concept Map populated\n",
      "................\n",
      "Content Model populated\n",
      "................\n",
      "Content popularity score updated\n"
     ]
    }
   ],
   "source": [
    "# mocks the data for Pratham usecase V1 and recommends content based on content popularity\n",
    "import csv\n",
    "import sys\n",
    "import collections\n",
    "import os.path\n",
    "import requests\n",
    "\n",
    "# on exit clean-ups\n",
    "import atexit\n",
    "\n",
    "# cassandra libs\n",
    "from cassandra.cluster import Cluster\n",
    "from cassandra.query import dict_factory\n",
    "\n",
    "\n",
    "# neo4j libs\n",
    "from py2neo import Graph\n",
    "from py2neo import Node, Relationship\n",
    "from py2neo import authenticate\n",
    "from random import randint\n",
    "\n",
    "# neo4j graph connector\n",
    "authenticate(\"localhost:7474\", \"neo4j\", \"1sTep123\")\n",
    "graph = Graph()\n",
    "# delete entire graph\n",
    "graph.delete_all()\n",
    "\n",
    "\n",
    "\n",
    "# bool flag database connections\n",
    "cassandraDbOn=False\n",
    "neo4jDbOn=False\n",
    "\n",
    "def dbCleanUP(cassandraDbOn,neo4jDbOn):\n",
    "    if cassandraDbOn:\n",
    "    \tprint 'cleaning Cassandra state'\n",
    "    \tsession.shutdown();\n",
    "    \tcluster.shutdown();\n",
    "\n",
    "atexit.register(dbCleanUP,True,True)\n",
    "\n",
    "# setup cassandra connection\n",
    "cassandraDbOn=True\n",
    "cluster = Cluster()\n",
    "session = cluster.connect('learner_db')\n",
    "\n",
    "# set response schema to Dictionaries\n",
    "session.row_factory = dict_factory\n",
    "\n",
    "# process learner-db\n",
    "# move content summary table\n",
    "def movecontentsideloadingsummary():\n",
    "    graph = Graph()\n",
    "\n",
    "    cids = session.execute(\"SELECT DISTINCT content_id from content_sideloading_summary\")\n",
    "    for cid in cids:\n",
    "        uid = cid['content_id']\n",
    "        print(\"** Content:\",uid)\n",
    "\n",
    "        node=Node(\"Content\",id=uid)\n",
    "        graph.merge(node,\"Content\",\"id\")\n",
    "\n",
    "        contentDict = session.execute(\"SELECT * from content_sideloading_summary WHERE id='\" + uid + \"'\")[0]\n",
    "        cid = contentDict['content_id']\n",
    "        \n",
    "        #if (contentDict.has_key('total_count')):\n",
    "        #    total_count = contentDict['total_count']\n",
    "        #    node.properties['content_popularity'] = total_count\n",
    "        #    node.push()\n",
    "        node.properties['content_popularity'] = randint(1,100)\n",
    "        node.push()\n",
    "        \n",
    "        print('content: ', cid, 'content_popularity: ',total_count)\n",
    "\n",
    "# move concept map \n",
    "def moveConceptMap():\n",
    "    # neo4j graph connector\n",
    "    graph = Graph()\n",
    "    # delete entire graph\n",
    "\n",
    "    url=\"http://lp-sandbox.ekstep.org:8080/taxonomy-service/v2/analytics/domain/map\"\n",
    "    resp = requests.get(url).json()\n",
    "\n",
    "    # move all concepts\n",
    "    conceptList = resp[\"result\"][\"concepts\"]\n",
    "    for conceptDict in conceptList:\n",
    "        identifier=None\n",
    "        ASERlevel=None\n",
    "        if(not conceptDict.has_key('identifier')):\n",
    "            continue\n",
    "\n",
    "        identifier = conceptDict['identifier']\n",
    "        # create/find node\n",
    "        node = graph.merge_one(\"Concept\",\"id\",identifier)\n",
    "\n",
    "        if(conceptDict.has_key('subject')):\n",
    "            subject = conceptDict['subject']\n",
    "            node.properties[\"subject\"]=subject\n",
    "            node.push()\n",
    "\n",
    "        if(conceptDict.has_key('objectType')):\n",
    "            objectType = conceptDict['objectType']\n",
    "            node.properties[\"objectType\"]=objectType\n",
    "            node.push()\n",
    "        node.properties['tags'] =\"ASERlevel_\"+str(randint(1,5))\n",
    "        node.push()\n",
    "\n",
    "        # move all relations\n",
    "        relationList = resp[\"result\"][\"relations\"]\n",
    "    for relationDict in relationList:\n",
    "\n",
    "        if (not relationDict.has_key('startNodeId') ):\n",
    "            continue\n",
    "        if (not relationDict.has_key('endNodeId') ):\n",
    "            continue\n",
    "        if (not relationDict.has_key('relationType') ):\n",
    "            continue\n",
    "        startNodeId = relationDict['startNodeId']\n",
    "        endNodeId = relationDict['endNodeId']\n",
    "        relationType = relationDict['relationType']\n",
    "        node1 = graph.merge_one(\"Concept\",\"id\",startNodeId)\n",
    "        node2 = graph.merge_one(\"Concept\",\"id\",endNodeId)\n",
    "        graph.create(Relationship(node1, relationType, node2))\n",
    "\n",
    "def moveContentModel():\n",
    "    baseURL = \"http://lp-sandbox.ekstep.org:8080/taxonomy-service/v2/analytics/getContent/\"\n",
    "    listURL = \"http://lp-sandbox.ekstep.org:8080/taxonomy-service/v2/analytics/content/list\"\n",
    "\n",
    "    # neo4j graph connector\n",
    "    graph = Graph()\n",
    "    \n",
    "    url = listURL\n",
    "    resp = requests.get(url).json()\n",
    "    # no of content\n",
    "    contentList = resp[\"result\"][\"contents\"]\n",
    "    for contentListDict in contentList:\n",
    "        # check if there is an identifier for this content\n",
    "        if(not contentListDict.has_key('identifier')):\n",
    "            continue\n",
    "    \n",
    "        # check if there is an identifier for this content\n",
    "        identifier = contentListDict['identifier']\n",
    "\n",
    "        # create a node for this Content\n",
    "        node = graph.merge_one(\"Content\",\"id\",identifier)\n",
    "       \n",
    "        url = baseURL + identifier\n",
    "        resp = requests.get(url)\n",
    "\n",
    "        if(resp.status_code!=200):\n",
    "            continue\n",
    "\n",
    "        resp =  resp.json()\n",
    "\n",
    "        concept=None\n",
    "        Subject=None\n",
    "        ASERlevel=None\n",
    "        content_popularity=None\n",
    "        \n",
    "        contentDict = resp[\"result\"][\"content\"]\n",
    "\n",
    "    \n",
    "        if(contentDict.has_key('concepts')):\n",
    "            # this forms a \"relationship\" in the graph\n",
    "            concepts = contentDict['concepts']\n",
    "        \n",
    "        if(contentDict.has_key('Subject')):\n",
    "            # this forms a \"relationship\" in the graph\n",
    "            Subject = contentDict['Subject']\n",
    "            node.properties['Subject'] = Subject\n",
    "            node.push()\n",
    "            \n",
    "        node.properties['tags'] = \"ASERlevel_\"+str(randint(1,5))\n",
    "        node.push()\n",
    "        #updating content popularity as a tag\n",
    "        node.properties['content_popularity'] = randint(1,100)\n",
    "        node.push()\n",
    "\n",
    "print('................')\n",
    "moveConceptMap();\n",
    "print('Concept Map populated')\n",
    "# content model\n",
    "print('................')\n",
    "moveContentModel();\n",
    "print('Content Model populated')\n",
    "print('................')\n",
    "#movecontentsideloadingsummary();\n",
    "print('Content popularity score updated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recomended content for ASER level match:\n",
      "   | Content                      | tag         | popularity\n",
      "---+------------------------------+-------------+------------\n",
      " 1 | org.ekstep.num.scrn.basic    | ASERlevel_2 |         40\n",
      " 2 | org.ekstep.ordinal.worksheet | ASERlevel_2 |         18\n",
      " 3 | org.ekstep.math.magic        | ASERlevel_2 |         16\n",
      " 4 | numeracy_365                 | ASERlevel_2 |         13\n",
      "\n",
      "Recomended content for 'subject' level match :\n",
      "    | Content                       | tag         | popularity\n",
      "----+-------------------------------+-------------+------------\n",
      "  1 | org.ekstep.hindi.num.activity | ASERlevel_5 |         92\n",
      "  2 | numeracy_366                  | ASERlevel_5 |         87\n",
      "  3 | org.ekstep.addobj.worksheet   | ASERlevel_5 |         48\n",
      "  4 | org.ekstep.eng.num.activity   | ASERlevel_5 |         47\n",
      "  5 | org.ekstep.delta              | ASERlevel_5 |         41\n",
      "  6 | org.ekstep.time.worksheet     | ASERlevel_5 |         23\n",
      "  7 | numeracy_374                  | ASERlevel_4 |         70\n",
      "  8 | numeracy_377                  | ASERlevel_4 |         38\n",
      "  9 | numeracy_418                  | ASERlevel_4 |         36\n",
      " 10 | numeracy_382                  | ASERlevel_4 |         28\n",
      " 11 | org.ekstep.numchart.worksheet | ASERlevel_3 |         69\n",
      " 12 | org.ekstep.aser               | ASERlevel_3 |         12\n",
      " 13 | org.ekstep.money.worksheet    | ASERlevel_3 |          4\n",
      " 14 | org.ekstep.num.scrn.basic     | ASERlevel_2 |         40\n",
      " 15 | org.ekstep.ordinal.worksheet  | ASERlevel_2 |         18\n",
      " 16 | org.ekstep.math.magic         | ASERlevel_2 |         16\n",
      " 17 | numeracy_365                  | ASERlevel_2 |         13\n",
      " 18 | org.ekstep.counting.worksheet | ASERlevel_1 |         23\n",
      " 19 | org.ekstep.moreless.worksheet | ASERlevel_1 |          1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sub=\"numeracy\"\n",
    "level=\"ASERlevel_2\"\n",
    "#content for exact match of level\n",
    "contentRec1= graph.cypher.execute(\"MATCH (b:Content) WHERE (lower(b.Subject)=~ '(?i)\"+sub+\"') AND ( has(b.tags)) AND ('\"+level+\"' IN (b.tags))  Return b.id AS Content, b.tags AS tag, b.content_popularity AS popularity ORDER BY popularity DESC\")\n",
    "# content for match at domain level-optional match\n",
    "contentRec= graph.cypher.execute(\"MATCH (b:Content) WHERE lower(b.Subject)=~ '(?i)\"+sub+\"' OPTIONAL MATCH (b) WHERE ( has(b.tags)) AND ('\"+level+\"' IN (b.tags))  Return b.id AS Content, b.tags AS tag, b.content_popularity AS popularity ORDER BY tag DESC,popularity DESC\")\n",
    "\n",
    "print('Recomended content for ASER level match:')\n",
    "print(contentRec1)\n",
    "print('Recomended content for \\'subject\\' level match :')\n",
    "print(contentRec)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
