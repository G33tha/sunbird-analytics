{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "................\n",
      "Concept Map populated\n",
      "................\n",
      "Concept Map populated\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import csv\n",
    "import sys\n",
    "import collections\n",
    "import os.path\n",
    "import requests\n",
    "\n",
    "# on exit clean-ups\n",
    "import atexit\n",
    "\n",
    "# neo4j libs\n",
    "from py2neo import Graph\n",
    "from py2neo import Node, Relationship\n",
    "from py2neo import authenticate\n",
    "from random import randint\n",
    "\n",
    "# neo4j graph connector\n",
    "authenticate(\"localhost:7474\", \"neo4j\", \"1sTep123\")\n",
    "graph = Graph()\n",
    "# delete entire graph\n",
    "graph.delete_all()\n",
    "\n",
    "# move content summary table\n",
    "def moveContentSummaryTable():\n",
    "    graph = Graph()\n",
    "\n",
    "    lids = session.execute(\"SELECT DISTINCT learner_id from learnercontentsummary\")\n",
    "    for lid in lids:\n",
    "        uid = lid['learner_id']\n",
    "        print(\"** learner:\",uid)\n",
    "        # content_id text, interactions_per_min double,\n",
    "        #num_of_sessions_played int,\n",
    "        #time_spent double,\n",
    "        node=Node(\"Learner\",id=uid)\n",
    "        graph.merge(node,\"Learner\",\"id\")\n",
    "\n",
    "        contentDict = session.execute(\"SELECT * from learnercontentsummary WHERE learner_id='\" + uid + \"'\")[0]\n",
    "        cid = contentDict['content_id']\n",
    "        tsp = contentDict['time_spent']\n",
    "        ipm = contentDict['interactions_per_min']\n",
    "\n",
    "        node2 = graph.merge_one(\"Content\",\"id\",cid)\n",
    "        # add a relationship with property score\n",
    "        graph.create(Relationship(node, \"INTERACTED_WITH\", node2,timeSpent=tsp,ipm=ipm))\n",
    "        print('content: ', cid, 'tsp: ',tsp, 'ipm', ipm)\n",
    "\n",
    "\n",
    "\n",
    "# move proficiency table\n",
    "\n",
    "def moveContentModel():\n",
    "    baseURL = \"http://lp-sandbox.ekstep.org:8080/taxonomy-service/v2/analytics/getContent/\"\n",
    "    listURL = \"http://lp-sandbox.ekstep.org:8080/taxonomy-service/v2/analytics/content/list\"\n",
    "\n",
    "    # neo4j graph connector\n",
    "    graph = Graph()\n",
    "    \n",
    "    url = listURL\n",
    "    resp = requests.get(url).json()\n",
    "    # no of content\n",
    "    contentList = resp[\"result\"][\"contents\"]\n",
    "    for contentListDict in contentList:\n",
    "        # check if there is an identifier for this content\n",
    "        if(not contentListDict.has_key('identifier')):\n",
    "            continue\n",
    "    \n",
    "        # check if there is an identifier for this content\n",
    "        identifier = contentListDict['identifier']\n",
    "\n",
    "        # create a node for this Content\n",
    "        node = graph.merge_one(\"Content\",\"id\",identifier)\n",
    "       \n",
    "        url = baseURL + identifier\n",
    "        resp = requests.get(url)\n",
    "\n",
    "        if(resp.status_code!=200):\n",
    "            continue\n",
    "\n",
    "        resp =  resp.json()\n",
    "\n",
    "        concept=None\n",
    "        Subject=None\n",
    "        ASERlevel=None\n",
    "        \n",
    "        contentDict = resp[\"result\"][\"content\"]\n",
    "\n",
    "    \n",
    "        if(contentDict.has_key('concepts')):\n",
    "            # this forms a \"relationship\" in the graph\n",
    "            concepts = contentDict['concepts']\n",
    "        \n",
    "        if(contentDict.has_key('Subject')):\n",
    "            # this forms a \"relationship\" in the graph\n",
    "            Subject = contentDict['Subject']\n",
    "            node.properties['Subject'] = Subject\n",
    "            node.push()\n",
    "            \n",
    "        node.properties['tags'] = \"ASERlevel_\"+str(randint(1,5))\n",
    "        node.push()\n",
    "\n",
    "\n",
    "# move concept map \n",
    "def moveConceptMap():\n",
    "    # neo4j graph connector\n",
    "    graph = Graph()\n",
    "    # delete entire graph\n",
    "\n",
    "    url=\"http://lp-sandbox.ekstep.org:8080/taxonomy-service/v2/analytics/domain/map\"\n",
    "    resp = requests.get(url).json()\n",
    "\n",
    "    # move all concepts\n",
    "    conceptList = resp[\"result\"][\"concepts\"]\n",
    "    for conceptDict in conceptList:\n",
    "        identifier=None\n",
    "        ASERlevel=None\n",
    "        if(not conceptDict.has_key('identifier')):\n",
    "            continue\n",
    "\n",
    "        identifier = conceptDict['identifier']\n",
    "        # create/find node\n",
    "        node = graph.merge_one(\"Concept\",\"id\",identifier)\n",
    "\n",
    "        if(conceptDict.has_key('subject')):\n",
    "            subject = conceptDict['subject']\n",
    "            node.properties[\"subject\"]=subject\n",
    "            node.push()\n",
    "\n",
    "        if(conceptDict.has_key('objectType')):\n",
    "            objectType = conceptDict['objectType']\n",
    "            node.properties[\"objectType\"]=objectType\n",
    "            node.push()\n",
    "        node.properties['tags'] =\"ASERlevel_\"+str(randint(1,5))\n",
    "        node.push()\n",
    "\n",
    "        # move all relations\n",
    "        relationList = resp[\"result\"][\"relations\"]\n",
    "    for relationDict in relationList:\n",
    "\n",
    "        if (not relationDict.has_key('startNodeId') ):\n",
    "            continue\n",
    "        if (not relationDict.has_key('endNodeId') ):\n",
    "            continue\n",
    "        if (not relationDict.has_key('relationType') ):\n",
    "            continue\n",
    "        startNodeId = relationDict['startNodeId']\n",
    "        endNodeId = relationDict['endNodeId']\n",
    "        relationType = relationDict['relationType']\n",
    "        node1 = graph.merge_one(\"Concept\",\"id\",startNodeId)\n",
    "        node2 = graph.merge_one(\"Concept\",\"id\",endNodeId)\n",
    "        graph.create(Relationship(node1, relationType, node2))\n",
    "\n",
    "print('................')\n",
    "moveConceptMap();\n",
    "print('Concept Map populated')\n",
    "# content model\n",
    "print('................')\n",
    "moveContentModel();\n",
    "print('Concept Map populated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recomended content:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   | Content                      \n",
       "---+-------------------------------\n",
       " 1 | org.ekstep.addobj.worksheet  \n",
       " 2 | org.ekstep.counting.worksheet\n",
       " 3 | numeracy_382                 \n",
       " 4 | org.ekstep.delta             \n",
       " 5 | numeracy_418                 "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub=\"numeracy\"\n",
    "level=\"ASERlevel_1\"\n",
    "contentRec= graph.cypher.execute(\"MATCH(b:Content{Subject:'\"+sub+\"'}) WHERE ( has(b.tags)) AND ('\"+level+\"' IN b.tags ) Return b.id AS Content\")\n",
    "print('Recomended content:')\n",
    "contentRec\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
